{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "module_path \u003d os.path.abspath(os.path.join(\u0027..\u0027))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "import torch\n",
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "from src.dataloader.pointwise.data_fetcher import DataFetcher\n",
        "from src.utils.utils import create_node2vec_embedding_layer\n",
        "from tqdm import tqdm\n",
        "from src.model.pointwise.model_fm import HomophilyContentCNNFM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "\n",
        "from src.constants import DICTIONARY_PATH, MAX_LENGTH_USER_REPRESENATION, MAX_LENGTH_COMMENT_SECTION, ROOT_PATH\n",
        "import pickle "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "from src.model.pointwise.deepconn_model_fm import DeepCoNNFM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "from src.testing.evaluation_data import EvaluationData\n",
        "from src.testing.evaluation_dataset import EvaluationDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "torch.cuda.set_device(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": "user_embedding_path \u003d \u0027\u0027\nvalidation_author_path \u003d \u0027\u0027\nmodel_folder_path \u003d \u0027\u0027\nmodel_filename \u003d \u0027\u0027\nmodel_path \u003d model_folder_path + model_filename\ncomment_id_to_author_dict_path \u003d \u0027\u0027\nroot_path \u003d \u0027\u0027\ntraining_path \u003d \u0027\u0027\ntrain_set_path \u003d \u0027\u0027"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "NODE2VEC_EMB_DIM, num_authors, node2vec_emb_layer, author_to_pos_dict \u003d create_node2vec_embedding_layer(\n",
        "        user_embedding_path, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "validation_authors \u003d np.load(validation_author_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "comment_id_to_author_dict \u003d pickle.load(open(comment_id_to_author_dict_path, \u0027rb\u0027))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": "data_fetcher \u003d DataFetcher(training_path,\n                           train_set_path,\n                           gensim.corpora.Dictionary.load(DICTIONARY_PATH))\n\nevaluation_data \u003d EvaluationData(data_fetcher, comment_id_to_author_dict, author_to_pos_dict)\nevaluation_dataset \u003d EvaluationDataset()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "def load_own_model(path):\n",
        "    print(\u0027Load HomophilyCoNN\u0027)\n",
        "    NODE2VEC_EMB_DIM, num_authors, node2vec_emb_layer, author_to_pos_dict \u003d create_node2vec_embedding_layer(\n",
        "        user_embedding_path,\n",
        "        True)\n",
        "\n",
        "    checkpoint \u003d torch.load(path)\n",
        "    config \u003d checkpoint[\u0027config\u0027]\n",
        "    state_dict \u003d checkpoint[\u0027state_dict\u0027]\n",
        "\n",
        "    # del config[\u0027pairwise\u0027]\n",
        "\n",
        "    to_keep_set \u003d [\u0027node2vec_emb_layer\u0027, \u0027NODE2VEC_EMB_DIM\u0027,\n",
        "                   \u0027MAX_LENGTH_USER_REPRESENATION\u0027,\n",
        "                   \u0027MAX_LENGTH_COMMENT_SECTION\u0027,\n",
        "                   \u0027dropout\u0027,\n",
        "                   \u0027user_num_kernels\u0027,\n",
        "                   \u0027number of kernels\u0027,\n",
        "                   \u0027section_num_kernels\u0027,\n",
        "                   \u0027user_kernel_size\u0027,  # number of words in window\n",
        "                   \u0027section_kernel_size\u0027,\n",
        "                   \u0027latent_factors_deepconn\u0027,  # embedding size\n",
        "                   \u0027freeze_embeddings\u0027,\n",
        "                   \u0027latent_factors_user\u0027,\n",
        "                   \u0027latent_factors_section\u0027]\n",
        "\n",
        "    to_keep_set \u003d set(to_keep_set)\n",
        "\n",
        "    keys \u003d list(config.keys())\n",
        "    for k in keys:\n",
        "        if k not in to_keep_set:\n",
        "            del config[k]\n",
        "    print(config)\n",
        "    # new_state_dict \u003d OrderedDict()\n",
        "    # for k, v in state_dict.items():\n",
        "    #    name \u003d k[7:]  # remove `module.`\n",
        "    #    new_state_dict[name] \u003d v\n",
        "\n",
        "    model \u003d HomophilyContentCNNFM(node2vec_emb_layer,\n",
        "                                NODE2VEC_EMB_DIM,\n",
        "                                MAX_LENGTH_USER_REPRESENATION,\n",
        "                                MAX_LENGTH_COMMENT_SECTION,\n",
        "                                **config)\n",
        "    model.load_state_dict(state_dict)\n",
        "    return config[\u0027latent_factors_user\u0027], model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "latent_factors_user, model \u003d load_own_model(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "keyed_vectors \u003d KeyedVectors(vector_size\u003dlatent_factors_user)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "model.cuda()\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "for author_id in tqdm(validation_authors):\n",
        "    user_rep \u003d data_fetcher.get_user_representation(author_id, \u0027asdqwe\u0027)\n",
        "    user_content, user_emb, user_emb_offsets \u003d evaluation_data.get_author_data(author_id, user_rep)\n",
        "    user_emb, user_emb_offsets \u003d user_emb.cuda(), user_emb_offsets.cuda()\n",
        "    user_emb \u003d model.get_user_rep(user_content.unsqueeze(0).cuda(), user_emb, user_emb_offsets,)\n",
        "    keyed_vectors.add(str(author_id), user_emb.cpu().detach().numpy()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": "keyed_vectors.save_word2vec_format(model_folder_path + \u0027keyed_vectors.txt\u0027)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": "print(\u0027Output Path:\u0027, model_folder_path + \u0027keyed_vectors.txt\u0027)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}